# Data

## wikipedia

These are modified/cleaned excerpts from Wikipedia (English) with each paragraph on one line.

* python.txt - excerpt from https://en.wikipedia.org/wiki/Python_(programming_language)
* cologne.txt - excerpt from https://en.wikipedia.org/wiki/Cologne
* linguistics.txt - excerpt from https://en.wikipedia.org/wiki/Linguistics

Wikipedia texts are available under the [Creative Commons Attribution-ShareAlike License](https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License).

## tokenize

This folder contains two files/texts that can be tokenized.

* simple.txt contains one sentence that can be easily tokenized using a whitespace tokenizer.
* challenge.txt contains two sentences that pose some challenges for a tokenizer.

## Corpus of Contemporary American English (COCA)

## HUM19UK Corpus